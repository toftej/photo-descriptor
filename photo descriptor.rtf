{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red111\green14\blue195;\red246\green249\blue252;\red52\green55\blue54;
\red134\green86\blue3;\red164\green69\blue11;\red24\green112\blue43;\red22\green79\blue199;\red77\green80\blue85;
}
{\*\expandedcolortbl;;\cssrgb\c51765\c18824\c80784;\cssrgb\c97255\c98039\c99216;\cssrgb\c26667\c27843\c27451;
\cssrgb\c60000\c41176\c0;\cssrgb\c70980\c34902\c3137;\cssrgb\c9412\c50196\c21961;\cssrgb\c9804\c40392\c82353;\cssrgb\c37255\c38824\c40784;
}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
import\cf4  cv2\
\cf2 import\cf4  numpy \cf2 as\cf4  np\
\cf2 import\cf4  random\
\cf2 import\cf4  string\
\
\cf2 def\cf4  \cf5 generate_lot_number\cf4 (length=\cf6 10\cf4 ):\
  \cf7 """Generates a random lot number of a given length."""\cf4 \
  characters = string.ascii_uppercase + string.digits\
  lot_number = \cf7 ''\cf4 .join(random.choice(characters) \cf2 for\cf4  i \cf2 in\cf4  \cf8 range\cf4 (length))\
  \cf2 return\cf4  lot_number\
\
\cf2 def\cf4  \cf5 generate_title\cf4 (photo):\
  \cf7 """Generates a title for the photo based on its contents."""\cf4 \
  \cf9 # Use a pre-trained object detection model to identify the objects in the photo.\cf4 \
  object_detector = cv2.dnn.readNetFromDarknet(\cf7 'yolov3.cfg'\cf4 , \cf7 'yolov3.weights'\cf4 )\
  blob = cv2.dnn.blobFromImage(photo, \cf6 1\cf4 /\cf6 255\cf4 , (\cf6 416\cf4 , \cf6 416\cf4 ), \cf6 True\cf4 , swapRB=\cf6 True\cf4 , crop=\cf6 False\cf4 )\
  object_detector.setInput(blob)\
  detections = object_detector.forward()\
\
  \cf9 # Generate a title based on the detected objects.\cf4 \
  title = \cf7 ''\cf4 \
  \cf2 for\cf4  detection \cf2 in\cf4  detections:\
    class_id = \cf8 int\cf4 (detection[\cf6 0\cf4 ][\cf6 0\cf4 ])\
    confidence = detection[\cf6 0\cf4 ][\cf6 1\cf4 ]\
    \cf2 if\cf4  confidence > \cf6 0.5\cf4 :\
      class_name = COCO_LABELS[class_id]\
      title += class_name + \cf7 ' '\cf4 \
\
  \cf9 # Remove the trailing space from the title.\cf4 \
  title = title[:-\cf6 1\cf4 ]\
\
  \cf2 return\cf4  title\
\
\cf2 def\cf4  \cf5 generate_description\cf4 (photo):\
  \cf7 """Generates a description for the photo based on its contents."""\cf4 \
  \cf9 # Use a pre-trained image captioning model to generate a description for the photo.\cf4 \
  caption_generator = cv2.dnn.readNetFromTensorflow(\cf7 'show_and_tell.pb'\cf4 )\
  caption_generator.setInput(cv2.dnn.blobFromImage(photo, \cf6 1\cf4 /\cf6 255\cf4 , (\cf6 299\cf4 , \cf6 299\cf4 ), \cf6 True\cf4 , swapRB=\cf6 True\cf4 , crop=\cf6 False\cf4 ))\
  caption = caption_generator.forward()[\cf6 0\cf4 ]\
\
  \cf9 # Decode the caption from a one-hot encoding.\cf4 \
  caption_words = []\
  \cf2 for\cf4  i \cf2 in\cf4  \cf8 range\cf4 (\cf8 len\cf4 (caption)):\
    word_id = np.argmax(caption[i])\
    word = WORD_VOCAB_INVERTED[word_id]\
    caption_words.append(word)\
\
  \cf9 # Remove the END token from the caption.\cf4 \
  caption_words = caption_words[:-\cf6 1\cf4 ]\
\
  \cf9 # Join the caption words into a string.\cf4 \
  description = \cf7 ' '\cf4 .join(caption_words)\
\
  \cf2 return\cf4  description\
\
\cf2 def\cf4  \cf5 analyze_photo\cf4 (photo):\
  \cf7 """Analyzes the photo and generates a lot number, title, and description."""\cf4 \
  lot_number = generate_lot_number()\
  title = generate_title(photo)\
  description = generate_description(photo)\
\
  \cf2 return\cf4  lot_number, title, description\
\
\cf9 # Example usage:\cf4 \
\
photo = cv2.imread(\cf7 'photo.jpg'\cf4 )\
lot_number, title, description = analyze_photo(photo)\
\
print(\cf7 'Lot number:'\cf4 , lot_number)\
print(\cf7 'Title:'\cf4 , title)\
print(\cf7 'Description:'\cf4 , description)}